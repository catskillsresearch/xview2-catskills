{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Spacenet from snapshot on a single case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/catskills/Desktop/xview2-catskills/utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import cuda, serializers, Variable\n",
    "from inference import inference\n",
    "output='foo.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First do inference inside notebook to see how to apply the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer import cuda, serializers, Variable\n",
    "from segmentation import SegmentationModel as Model\n",
    "\n",
    "input='/home/catskills/Desktop/dataxv2/xBD/santa-rosa-wildfire/images/santa-rosa-wildfire_00000030_pre_disaster.png'\n",
    "trainfn='/home/catskills/Desktop/dataxv2/xBD/santa-rosa-wildfire/masks/santa-rosa-wildfire_00000030_pre_disaster.png'\n",
    "weights='/home/catskills/Desktop/dataxv2/release/v_catskills_0.2.1/localization.hdf5'\n",
    "mean='/home/catskills/Desktop/xview2-catskills/weights/mean.npy'\n",
    "sys.path.append('../src/models')\n",
    "mean = np.load(mean)\n",
    "model = Model(weights, mean)\n",
    "image = np.array(Image.open(input))\n",
    "train=np.array(Image.open(trainfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = rgb2gray(np.array(Image.open(trainfn)))>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.apply_segmentation(image)\n",
    "building_mask_pred = (np.argmax(score, axis=0) == 1)\n",
    "bm_only = (building_mask_pred & ~train).astype(int)*9\n",
    "train_only=(train & ~building_mask_pred).astype(int)*3\n",
    "bm_and_tr=(building_mask_pred & train).astype(int)*6\n",
    "all = bm_only + train_only + bm_and_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overtrain Santa Rosa 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_cpu(x):\n",
    "    return float(cuda.to_cpu(x.data))\n",
    "\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model._SegmentationModel__model);\n",
    "\n",
    "train_int = train.astype(int)\n",
    "gt=np.array([train_int])\n",
    "gt_in = Variable(cuda.cupy.asarray(gt, dtype=cuda.cupy.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] n_gt 34 n_pred 65 poly_loss 91.2% softmax_loss 6.4% loss 42.882% accuracy 97.634220%\n",
      "[1] n_gt 34 n_pred 67 poly_loss 97.1% softmax_loss 5.3% loss 44.145% accuracy 97.947884%\n",
      "[2] n_gt 34 n_pred 61 poly_loss 79.4% softmax_loss 4.7% loss 36.464% accuracy 98.223114%\n",
      "[3] n_gt 34 n_pred 51 poly_loss 50.0% softmax_loss 4.3% loss 24.267% accuracy 98.407841%\n",
      "[4] n_gt 34 n_pred 48 poly_loss 41.2% softmax_loss 4.0% loss 20.422% accuracy 98.499393%\n",
      "[5] n_gt 34 n_pred 39 poly_loss 14.7% softmax_loss 3.7% loss 9.594% accuracy 98.561192%\n",
      "[6] n_gt 34 n_pred 44 poly_loss 29.4% softmax_loss 3.5% loss 15.282% accuracy 98.608589%\n",
      "[7] n_gt 34 n_pred 42 poly_loss 23.5% softmax_loss 3.3% loss 12.760% accuracy 98.654652%\n",
      "[8] n_gt 34 n_pred 41 poly_loss 20.6% softmax_loss 3.2% loss 11.432% accuracy 98.705292%\n",
      "[9] n_gt 34 n_pred 40 poly_loss 17.6% softmax_loss 3.1% loss 10.124% accuracy 98.756409%\n"
     ]
    }
   ],
   "source": [
    "image_in, crop = model._SegmentationModel__preprocess(image)\n",
    "\n",
    "from imantics import Mask\n",
    "\n",
    "from simplification.cutil import simplify_coords_vwp\n",
    "\n",
    "def predict_polygons(polygons):\n",
    "    new_predictions = []\n",
    "    for poly in polygons:\n",
    "        if len(poly) >= 3:\n",
    "            f = poly.reshape(-1, 2)\n",
    "            simplified_vw = simplify_coords_vwp(f, .3)\n",
    "            if len(simplified_vw) > 2:\n",
    "                    mpoly = []\n",
    "                    # Rebuilding the polygon in the way that PIL expects the values [(x1,y1),(x2,y2)]\n",
    "                    for i in simplified_vw:\n",
    "                        mpoly.append((i[0], i[1]))\n",
    "                    # Adding the first point to the last to close the polygon\n",
    "                    mpoly.append((simplified_vw[0][0], simplified_vw[0][1]))\n",
    "                    new_predictions.append(mpoly)\n",
    "    return new_predictions\n",
    "\n",
    "def polygon_loss(score_cuda, n_gt_polygons):\n",
    "    score1 = F.softmax(score_cuda)\n",
    "    score1_cpu = cuda.to_cpu(score1.data)[0]\n",
    "    building_mask_pred = (np.argmax(score1_cpu, axis=0) == 1)\n",
    "    polygons_pred = Mask(building_mask_pred).polygons()\n",
    "    n_polygons_pred = len(predict_polygons(polygons_pred))\n",
    "    if n_gt_polygons == 0 and n_polygons_pred > 0:\n",
    "        poly_loss = 1\n",
    "    else: \n",
    "        poly_loss = abs(n_polygons_pred-n_gt_polygons)/n_gt_polygons\n",
    "    return poly_loss, n_gt_polygons, n_polygons_pred\n",
    "\n",
    "gt_polygons = Mask(train).polygons()\n",
    "\n",
    "n_gt_polygons = len(predict_polygons(gt_polygons))\n",
    "\n",
    "for i in range(10):\n",
    "    with chainer.using_config('train', True):\n",
    "        score_cuda = model._SegmentationModel__model.forward(image_in)\n",
    "        loss = F.softmax_cross_entropy(score_cuda, gt_in)    \n",
    "        poly_loss, n_gt, n_pred = polygon_loss(score_cuda, n_gt_polygons)\n",
    "        softmax_loss = float_to_cpu(loss)\n",
    "        loss += 0.4*poly_loss\n",
    "        accuracy=float_to_cpu(F.accuracy(score_cuda, gt_in))\n",
    "        print(f'[{i}] n_gt {n_gt} n_pred {n_pred} poly_loss {100*poly_loss:.1f}% softmax_loss {100*softmax_loss:.1f}% loss {100*float_to_cpu(loss):.3f}% accuracy {100*accuracy:.6f}%')\n",
    "        model._SegmentationModel__model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with chainer.using_config('train', True):\n",
    "    score_cuda= model._SegmentationModel__model.forward(image_in)\n",
    "score_cuda_softmax = F.softmax(score_cuda)\n",
    "score_cpu = cuda.to_cpu(score_cuda_softmax.data)[0]\n",
    "top, left, bottom, right = crop\n",
    "score_cpu = score_cpu[:, top:bottom, left:right]\n",
    "building_mask_pred = (np.argmax(score_cpu, axis=0) == 1)\n",
    "\n",
    "bm_only = (building_mask_pred & ~train).astype(int)*9\n",
    "train_only=train & ~building_mask_pred.astype(int)*3\n",
    "bm_and_tr=(building_mask_pred & train).astype(int)*6\n",
    "all = bm_only + train_only + bm_and_tr\n",
    "plt.figure(figsize=(10,10));\n",
    "plt.imshow(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(building_mask_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(building_mask_pred & ~train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(~building_mask_pred & train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(building_mask_pred ^ train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import serializers\n",
    "new_weights='model_updated.hdf5'\n",
    "serializers.save_npz(new_weights, model._SegmentationModel__model)\n",
    "\n",
    "import chainer.computational_graph as c\n",
    "g = c.build_computational_graph(score_cuda)\n",
    "with open('loss.dot', 'w') as o:\n",
    "    o.write(g.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xview2",
   "language": "python",
   "name": "xview2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
