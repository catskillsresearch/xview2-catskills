{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " My to-do list:\n",
    "- Diagram training process\n",
    "- Add filters for bad chips (in distribution tails at levels that look like nonsense) for training -- do this once in preprocessing of \"cleaned xBD\" directory\n",
    "- TTS model from baseline for damage\n",
    "- Keras manual training loop in Jupyter\n",
    "- Use CPU for inference\n",
    "- Maybe recode baseline in chainer if I can figure out how to transfer the weights, so I can work in a single package and single process\n",
    "- detect bad chips\n",
    "- SR 30 end to end 100%\n",
    "- 1 example for each disaster and damage type 100%\n",
    "- threshold size for localization to reduce   fragments\n",
    "- break out all scores per chip to spot hard cases systematically\n",
    "- use image display liberally on all steps in process flow for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try making the smallest set of images that contains one of each incident and per incident one of each damage level, then see if I can overtrain my model individually to match grou d truth for each of these images.   This is to verify sizing and capacity.  And shake out bugs like the 1 pixel chips.  Then worry about training and then take all the money.  The plan should always end with take all the money, not some ego preserving excuse about self betterment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/keras-custom-training-loop-59ce779d60fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "import cv2\n",
    "import datetime\n",
    "\n",
    "import shapely.wkt\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Configurations\n",
    "NUM_WORKERS = 4\n",
    "NUM_CLASSES = 4\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 120\n",
    "LEARNING_RATE = 0.0001\n",
    "RANDOM_SEED = 123\n",
    "LOG_STEP = 150\n",
    "\n",
    "damage_intensity_encoding = defaultdict(lambda: 0)\n",
    "damage_intensity_encoding['destroyed'] = 3\n",
    "damage_intensity_encoding['major-damage'] = 2\n",
    "damage_intensity_encoding['minor-damage'] = 1\n",
    "damage_intensity_encoding['no-damage'] = 0\n",
    "\n",
    "def process_img(img_array, polygon_pts, scale_pct):\n",
    "    \"\"\"Process Raw Data into\n",
    "\n",
    "            Args:\n",
    "                img_array (numpy array): numpy representation of image.\n",
    "                polygon_pts (array): corners of the building polygon.\n",
    "\n",
    "            Returns:\n",
    "                numpy array: .\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    height, width, _ = img_array.shape\n",
    "\n",
    "    xcoords = polygon_pts[:, 0]\n",
    "    ycoords = polygon_pts[:, 1]\n",
    "    xmin, xmax = np.min(xcoords), np.max(xcoords)\n",
    "    ymin, ymax = np.min(ycoords), np.max(ycoords)\n",
    "\n",
    "    xdiff = xmax - xmin\n",
    "    ydiff = ymax - ymin\n",
    "\n",
    "    #Extend image by scale percentage\n",
    "    xmin = max(int(xmin - (xdiff * scale_pct)), 0)\n",
    "    xmax = min(int(xmax + (xdiff * scale_pct)), width)\n",
    "    ymin = max(int(ymin - (ydiff * scale_pct)), 0)\n",
    "    ymax = min(int(ymax + (ydiff * scale_pct)), height)\n",
    "\n",
    "    (X,Y,Z)=img_array.shape\n",
    "    \n",
    "    if not(0 <= xmin < X and 0 < xmax <= X and 0 <= ymin < Y and 0 < ymax <= Y):\n",
    "        print(f'X: xmin {xmin}, xmax {xmax}, X {X}; Y: ymin {ymin}, ymax {ymax}, Y {Y}')\n",
    "        assert 0 <= xmin < X and 0 < xmax <= X and 0 <= ymin < Y and 0 < ymax <= Y\n",
    "    \n",
    "    return img_array[ymin:ymax, xmin:xmax, :]\n",
    "\n",
    "input_path='/home/catskills/Desktop/dataxv2/xBD'\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "disasters = [folder for folder in os.listdir(input_path) if not folder.startswith('.')]\n",
    "disaster_paths = ([input_path + \"/\" +  d + \"/images\" for d in disasters])\n",
    "image_paths = []\n",
    "image_paths.extend([(disaster_path + \"/\" + pic) for pic in os.listdir(disaster_path)] for disaster_path in disaster_paths)\n",
    "img_paths = np.concatenate(image_paths)\n",
    "\n",
    "image_info=[]\n",
    "\n",
    "for img_path in img_paths:\n",
    "    img_obj = Image.open(img_path)\n",
    "    img_array = np.array(img_obj)\n",
    "    label_path = img_path.replace('png', 'json').replace('images', 'labels')\n",
    "    label_file = open(label_path)\n",
    "    label_data = json.load(label_file)\n",
    "    for feat in label_data['features']['xy']:\n",
    "        try:\n",
    "            damage_type = feat['properties']['subtype']\n",
    "        except: # pre-disaster damage is default no-damage\n",
    "            damage_type = \"no-damage\"\n",
    "            continue\n",
    "        polygon_geom = shapely.wkt.loads(feat['wkt'])\n",
    "        polygon_pts = np.array(list(polygon_geom.exterior.coords))\n",
    "        poly_img = process_img(img_array, polygon_pts, 0.8)\n",
    "        image_info.append((poly_img.shape, img_path, feat['properties']['uid'], poly_img))\n",
    "    if img_path=='/home/catskills/Desktop/dataxv2/xBD/mexico-earthquake/images/mexico-earthquake_00000168_post_disaster.png':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1\n"
     ]
    }
   ],
   "source": [
    "oneA = [x for x in image_info if x[0][0] ==1]\n",
    "oneB = [x for x in image_info if x[0][1] ==1]\n",
    "big=[x for x in image_info if x[0][0]*x[0][1]>1000**2]\n",
    "\n",
    "print(len(oneA),len(oneB),len(big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3bc0bce6de84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plt.imshow(oneA[0][-1])\n",
    "plt.title(oneA[0][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(oneB[0][-1])\n",
    "plt.title(oneB[0][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(big[0][-1])\n",
    "plt.title(big[0][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x[0:2],y,z) for x,y,z,w in oneB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x[0:2],y,z) for x,y,z,w in big]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=oneA[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat['properties']['uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat['wkt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    img_info=[]\n",
    "    img_obj = Image.open(img_path)\n",
    "    img_array = np.array(img_obj)\n",
    "    label_path = img_path.replace('png', 'json').replace('images', 'labels')\n",
    "    label_file = open(label_path)\n",
    "    label_data = json.load(label_file)\n",
    "    for feat in label_data['features']['xy']:\n",
    "        try:\n",
    "            damage_type = feat['properties']['subtype']\n",
    "        except: # pre-disaster damage is default no-damage\n",
    "            damage_type = \"no-damage\"\n",
    "            continue\n",
    "        polygon_geom = shapely.wkt.loads(feat['wkt'])\n",
    "        polygon_pts = np.array(list(polygon_geom.exterior.coords))\n",
    "        poly_img = process_img(img_array, polygon_pts, 0.8)\n",
    "        img_info.append((poly_img.shape, img_path, feat['properties']['uid'], poly_img))\n",
    "        if poly_img.shape[0]==1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(poly_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat['wkt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "polygon_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polygon_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(polygon_pts[:,0], polygon_pts[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "fns=glob('/home/catskills/Desktop/dataxv2/classifier/*.png')\n",
    "dimensions=set([io.imread(fn).shape[0:2] for fn in fns])\n",
    "len(dimensions)\n",
    "\n",
    "d=list(dimensions)\n",
    "X=np.array([x for x,y in dimensions])\n",
    "Y=np.array([y for x,y in dimensions])\n",
    "\n",
    "X.min(), X.max(), Y.min(), Y.max()\n",
    "\n",
    "[(x,y) for (x,y) in dimensions if x==1 or y==1]M\n",
    "\n",
    "S=list(sorted([np.sqrt(x*y) for x,y in dimensions]))\n",
    "plt.hist(S,bins=100);MM\n",
    "\n",
    "dimensions=[(fn,)+io.imread(fn).shape[0:2] for fn in fns]\n",
    "[fn for fn,x,y in dimensions if x>1000 and y>1000]\n",
    "\n",
    "bigs=[fn for fn,x,y in dimensions if x>1000 and y>1000]\n",
    "\n",
    "plt.imshow(io.imread(bigs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xview2",
   "language": "python",
   "name": "xview2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
